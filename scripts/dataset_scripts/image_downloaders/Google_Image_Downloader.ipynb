{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/hellock/icrawler\n",
    "# https://icrawler.readthedocs.io/en/latest/builtin.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icrawler.builtin import GoogleImageCrawler\n",
    "from datetime import date\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crawler_for_date(start_date, search_keyword, _type):\n",
    "    google_crawler = GoogleImageCrawler(\n",
    "        feeder_threads=4,\n",
    "        parser_threads=4,\n",
    "        downloader_threads=4,\n",
    "        storage={'root_dir': f'google_img/{search_keyword}/{search_keyword}_{_type}/{search_keyword}_{_type}_images_{start_date}'})\n",
    "\n",
    "    return google_crawler\n",
    "\n",
    "'''\n",
    "create_filter: creates a filter for GoogleImageCrawler\n",
    "\n",
    "params:\n",
    "start_date: 3-tuple (yyyy,m, d)\n",
    "end_date: 3-tuple (yyyy,m, d)\n",
    "\n",
    "# licenses: https://support.google.com/websearch/answer/29508?hl=en\n",
    "            https://www.google.com/advanced_image_search\n",
    "returns:\n",
    "\n",
    "filter with specified dates\n",
    "'''\n",
    "\n",
    "def create_filter(start_date, end_date, _type):\n",
    "\n",
    "    filters = dict(\n",
    "        size='large',\n",
    "        color='color',\n",
    "#         #license='commercial,modify',\n",
    "        date=(start_date, end_date)\n",
    "    )\n",
    "\n",
    "    if _type.strip() != '':\n",
    "        filters = dict(\n",
    "            type = _type,\n",
    "            size='large',\n",
    "            color='color',\n",
    "    #         #license='commercial,modify',\n",
    "            date=(start_date, end_date)\n",
    "        )\n",
    "    \n",
    "    return filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_search_keywords = ['selfie', 'wefie', 'faces','people','portrait']\n",
    "_search_keywords = ['medium shot', 'medium close up']\n",
    "\n",
    "_search_keywords = ['medium shot group picture', 'medium shot group photo']\n",
    "_search_keywords = ['group picture', 'group photo']\n",
    "_search_keywords = ['mirror selfie', 'medium long shot']\n",
    "\n",
    "_types = ['face','photo','']\n",
    "\n",
    "\n",
    "\n",
    "start_date = date(2012, 1, 1)\n",
    "delta = timedelta(days = 180)\n",
    "\n",
    "today = date.today()\n",
    "\n",
    "end_date = start_date + delta\n",
    "\n",
    "for _search_keyword in _search_keywords:\n",
    "    \n",
    "    for _type in _types:\n",
    "        \n",
    "        while(end_date < today):\n",
    "\n",
    "            print(_search_keyword, \", type:\", _type)\n",
    "\n",
    "            print(start_date.year, start_date.month, start_date.day)\n",
    "            print(end_date.year, end_date.month, end_date.day)\n",
    "            print('*******************************************************************************')\n",
    "\n",
    "\n",
    "            filters = create_filter((start_date.year, start_date.month, start_date.day), (end_date.year, end_date.month, end_date.day), _type)\n",
    "            google_crawler = get_crawler_for_date(start_date.strftime('%d_%b_%Y'), _search_keyword.replace(' ','_'), _type)\n",
    "            google_crawler.crawl(keyword=_search_keyword, filters=filters, max_num=1000, file_idx_offset=0)\n",
    "            print('*******************************************************************************')\n",
    "\n",
    "            start_date = start_date + delta + timedelta(days = 1) \n",
    "            end_date = start_date + delta\n",
    "\n",
    "        end_date = today\n",
    "        print('*******************************************************************************')\n",
    "        print(start_date.year, start_date.month, start_date.day)\n",
    "        print(end_date.year, end_date.month, end_date.day)\n",
    "\n",
    "        filters = create_filter((start_date.year, start_date.month, start_date.day), (end_date.year, end_date.month, end_date.day), _type)\n",
    "        google_crawler = get_crawler_for_date(start_date.strftime('%d_%b_%Y'), _search_keyword.replace(' ','_'), _type)\n",
    "        google_crawler.crawl(keyword=_search_keyword, filters=filters, max_num=1000, file_idx_offset=0)\n",
    "\n",
    "        print('*******************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
